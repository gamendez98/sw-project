{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizando y depurando tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import textrazor, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/semantic_web_project_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogiendo los tópicos de **Babelfy** que cuenten con enlace a DBpedia y tengan un score de mínimo 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "babelify_topics_new = []\n",
    "for i in range(len(data)):\n",
    "    tops = data[\"topics_babelify\"].iloc[i]\n",
    "    new_tops = []\n",
    "    if tops is not None:\n",
    "        try:\n",
    "            tops = eval(tops)\n",
    "        except:\n",
    "            if math.isnan(tops):\n",
    "                babelify_topics_new.append(new_tops)\n",
    "                continue\n",
    "        for t in tops:\n",
    "            if t[\"DBpediaURL\"] != \"\" and t[\"score\"] > 0.5:\n",
    "                new_tops.append(t)\n",
    "    babelify_topics_new.append(new_tops)\n",
    "\n",
    "data[\"topics_babelify\"] = babelify_topics_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['topics_textrazor'] = data['topics_textrazor'].apply(lambda x: [] if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar topicos repetidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_repeated_topics_babelfy(topics_babelfy):\n",
    "    try:\n",
    "        topics_babelfy = eval(topics_babelfy)\n",
    "    except:\n",
    "        pass\n",
    "    new_topics = []\n",
    "    topics_urls = []\n",
    "    for top in topics_babelfy:\n",
    "        if top[\"DBpediaURL\"] not in topics_urls:\n",
    "            new_topics.append(top)\n",
    "            topics_urls.append(top[\"DBpediaURL\"])\n",
    "    return new_topics \n",
    "\n",
    "def remove_repeated_topics_textrazor(topics_textrazor):\n",
    "    try:\n",
    "        topics_textrazor = eval(topics_textrazor)\n",
    "    except:\n",
    "        pass\n",
    "    new_topics = []\n",
    "    topics_ids = []\n",
    "    for top in topics_textrazor:\n",
    "        if top[\"topic_wikidata_id\"] not in topics_ids:\n",
    "            new_topics.append(top)\n",
    "            topics_ids.append(top[\"topic_wikidata_id\"])\n",
    "    return new_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"topics_babelify\"] = data[\"topics_babelify\"].apply(remove_repeated_topics_babelfy)\n",
    "data[\"topics_textrazor\"] = data[\"topics_textrazor\"].apply(remove_repeated_topics_textrazor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estableciendo un umbral para el score de coherencia de **Babelfy.** Este representa qué tanto se conecta el fragmento con respecto a todos los demás obtenidos. Proponemos un umbral de 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_score_threshold(topics_babelfy):\n",
    "    try:\n",
    "        topics_babelfy = eval(topics_babelfy)\n",
    "    except:\n",
    "        pass\n",
    "    new_topics = []\n",
    "    for top in topics_babelfy:\n",
    "        if top[\"coherenceScore\"] >= 0.2:\n",
    "            new_topics.append(top)\n",
    "    return new_topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"topics_babelify\"] = data[\"topics_babelify\"].apply(coherence_score_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracción adicional de papers que quedaron sin tópicos por parte de ambas plataformas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_babelify = data[\"topics_babelify\"].apply(lambda x: isinstance(x, list) and len(x) == 0)\n",
    "mask_textrazor = data[\"topics_textrazor\"].apply(lambda x: isinstance(x, list) and len(x) == 0)\n",
    "\n",
    "mask_combined = mask_babelify & mask_textrazor\n",
    "rows_with_empty_lists = data.loc[mask_combined]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semanticId</th>\n",
       "      <th>topics_babelify</th>\n",
       "      <th>topics_textrazor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>93031891bb1492c9533eceb77534b9192d8dc627</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>5bf171259e1ebfe1a438b54f1bc1056a363da75f</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2800</th>\n",
       "      <td>1cadd921cde096642c967a9a4fa9059848382cf0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>c9ec302f2646c2421e7fd449dd63b2e3d81f70ad</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7962</th>\n",
       "      <td>1aa6a6574a5919fd1ce5b773c1651633e9ec0d3d</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7966</th>\n",
       "      <td>bf2868365117a379139076b0cf30557fc738df07</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8012</th>\n",
       "      <td>17449db4decff5fa3cc21829cadf3be366c420b9</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>2b2cee5161cb553014688f684ee4b245a11371ac</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8083</th>\n",
       "      <td>af9eb1b2bf28030716482f3e77dc74704facf27f</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>393 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    semanticId topics_babelify  \\\n",
       "754                                        NaN              []   \n",
       "1488  93031891bb1492c9533eceb77534b9192d8dc627              []   \n",
       "2796  5bf171259e1ebfe1a438b54f1bc1056a363da75f              []   \n",
       "2800  1cadd921cde096642c967a9a4fa9059848382cf0              []   \n",
       "2806  c9ec302f2646c2421e7fd449dd63b2e3d81f70ad              []   \n",
       "...                                        ...             ...   \n",
       "7962  1aa6a6574a5919fd1ce5b773c1651633e9ec0d3d              []   \n",
       "7966  bf2868365117a379139076b0cf30557fc738df07              []   \n",
       "8012  17449db4decff5fa3cc21829cadf3be366c420b9              []   \n",
       "8028  2b2cee5161cb553014688f684ee4b245a11371ac              []   \n",
       "8083  af9eb1b2bf28030716482f3e77dc74704facf27f              []   \n",
       "\n",
       "     topics_textrazor  \n",
       "754                []  \n",
       "1488               []  \n",
       "2796               []  \n",
       "2800               []  \n",
       "2806               []  \n",
       "...               ...  \n",
       "7962               []  \n",
       "7966               []  \n",
       "8012               []  \n",
       "8028               []  \n",
       "8083               []  \n",
       "\n",
       "[393 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_with_empty_lists[[\"semanticId\", \"topics_babelify\", \"topics_textrazor\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_18988\\1953963395.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rows_with_empty_lists.drop([\"topics_babelify\", \"topics_textrazor\"], axis = 1, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "rows_with_empty_lists.drop([\"topics_babelify\", \"topics_textrazor\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para estos vamos a obtener nuevamente sus tópicos bajando el umbral a mínimo un 0.2 de puntaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "393it [03:46,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "textrazor.api_key = \"your_api_key_here\"\n",
    "client = textrazor.TextRazor(extractors=[\"topics\"])\n",
    "client.set_language_override(\"eng\")\n",
    "topics_textrazor_missing = []\n",
    "\n",
    "for _, row in tqdm(rows_with_empty_lists.iterrows()):\n",
    "    title = row[\"title\"]\n",
    "    abstract = row[\"abstract\"]\n",
    "    full_text = f\"{title}\\n{abstract}\"\n",
    "    response = client.analyze(full_text)\n",
    "    if response.ok:\n",
    "        textrazor_response = []\n",
    "        for topic in response.topics():\n",
    "            if topic.score > 0.2:\n",
    "                textrazor_response.append({\n",
    "                    \"topic_name\" : topic.label,\n",
    "                    \"topic_score\" : topic.score,\n",
    "                    \"topic_wikidata_id\" : topic.wikidata_id\n",
    "                })\n",
    "        topics_textrazor_missing.append({\n",
    "                    \"semanticId\": row[\"semanticId\"],\n",
    "                    \"topics_textrazor\": textrazor_response\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_empty_lists = pd.merge(rows_with_empty_lists, pd.DataFrame(topics_textrazor_missing), on = \"semanticId\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los tópicos de **Babelfy** vamos a buscar el mismo umbral de 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results = []\n",
    "with open(\"data/babelify_topics.json\", \"r\", encoding=\"utf-8\") as input_file:\n",
    "    for row in input_file:\n",
    "        topic_results.append(json.loads(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_empty_lists = pd.merge(rows_with_empty_lists, pd.DataFrame(topic_results), on = \"semanticId\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "babelify_topics_new = []\n",
    "for i in range(len(rows_with_empty_lists)):\n",
    "    try:\n",
    "        tops = rows_with_empty_lists[\"topics_babelify\"].iloc[i]\n",
    "        new_tops = []\n",
    "        if tops is not None:\n",
    "            for t in tops:\n",
    "                if t[\"DBpediaURL\"] != \"\" and t[\"score\"] > 0.2:\n",
    "                    new_tops.append(t)\n",
    "    except:\n",
    "        new_tops = []\n",
    "    babelify_topics_new.append(new_tops)\n",
    "\n",
    "rows_with_empty_lists[\"topics_babelify\"] = babelify_topics_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unimos y corroboramos la máscara otra vez. Solo la instancia con ``semanticId`` nulo permanece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_empty_lists = rows_with_empty_lists[[\"semanticId\", \"topics_babelify\", \"topics_textrazor\"]].dropna()\n",
    "indexes_ = data[data[\"semanticId\"].isin(rows_with_empty_lists[\"semanticId\"])].index\n",
    "for id_ in rows_with_empty_lists[\"semanticId\"]:\n",
    "    data.loc[indexes_, \"topics_babelify\"] = rows_with_empty_lists[\"topics_babelify\"]\n",
    "    data.loc[indexes_, \"topics_textrazor\"] = rows_with_empty_lists[\"topics_textrazor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>semanticId</th>\n",
       "      <th>topics_babelify</th>\n",
       "      <th>topics_textrazor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    semanticId topics_babelify topics_textrazor\n",
       "754        NaN              []               []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_babelify = data[\"topics_babelify\"].apply(lambda x: isinstance(x, list) and len(x) == 0)\n",
    "mask_textrazor = data[\"topics_textrazor\"].apply(lambda x: isinstance(x, list) and len(x) == 0)\n",
    "\n",
    "mask_combined = mask_babelify & mask_textrazor\n",
    "data.loc[mask_combined][[\"semanticId\", \"topics_babelify\", \"topics_textrazor\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/semantic_web_project_data_depurated.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
